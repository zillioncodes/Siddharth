BIG-DATA CONTENT RETRIEVAL, STORAGE AND ANALYSIS FOUNDATIONS OF DATA-INTENSIVE COMPUTING

Steps to run the programm.

Hadoop Installation Guide: 
1)Follow the steps mentioned into the guide : https://drive.google.com/file/d/0BweVwq32koypbjd6T19QWmhUZlU/edit?usp=sharing

Data Collection:
1) Unzip Utility.zip
2) Open the TweetCollector into eclipse.
3) Run the tweetCollector program.The Program collects the twitter using streaming API.
4) The Format of the tweet Data collected is Tweettext,Date,retweetCount,UserName,follower.
5) A new Folder "Data" is created into the solution file which stores collected data. Now this data can be used for map reduce program.

R Script:
1) Unzip Utility.zip
2) You can see the R script which has all the code to generate all the graphs on output data.

Start Hadoop:
1) Now start hdfs and yarn using "start-dfs.sh" and "yarn-dfs.sh".
2) Create a input directory if not present in your hdfs using "hdfs dfs -mkdir /input" command.

wordcount (calculate word ,hasgtag,@ count)
1) Unzip the Proj2Q1 ZipFile.
2) Go into the code folder and import wordcount.zip into your eclipse.
3) Now you can change the code and create a jar accordingly.
4) Now login into hduser using terminal and copy the jar file to your hduser. Use this command "cp /home/user/wordcount.jar ."
5) This will copy the jar file int your hduser you can view the file using "ls" command.
6) Now copy tweet.txt into input directory using "hdfs dfs -copyFromLocal /home/hduser/tweet.txt /input" command.
7) Now to run this code type "hadoop jar wordcount-sample.jar sample.WordCount"
8) The program creats an output directory and dumps the output file into it to see the output file type "hdfs dfs -ls /output". 
9) For your convinience we have also provided jar file which can be directly run.
10) You can also find the graphs generated by R in graphs folder.

CoOccurence (calculate count of co-occurring hash tags)
1) Unzip the Proj2Q2 ZipFile.
2) Follow the same steps as above mentioned in wordcount.
3) You can also find the graphs generated by R in graphs folder.

KMeansAlgorithm (Clusters the user according to follower count)
1) Unzip the Project2-question3 ZipFile.
2) Follow the same steps as above mentioned in wordcount.
3) Finally you will also get 3 files centroid1.txt, centroid2.txt, centroid3.txt, which will contain centroid value at each iteration.
4) You can also find the graphs generated by R in graphs folder.

DijkstrasAlgorithm (calculate single source shortestpath for all nodes)
1) Open the ZipFile into eclipse.
2) Follow the same steps as above mentioned in wordcount.
3) You can find the graphs created by GEPHI in graphs folder.
